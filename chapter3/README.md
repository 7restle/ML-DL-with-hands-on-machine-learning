# Chapter3 분류

## 3.1 MNIST
고등학생과 미국 인구 조사국 직원들이 손으로 쓴 숫자, 총 70000개의 작은 이미지로 만들어짐  
fetch_openml로 반환한 MNIST 데이터셋은 훈련세트와 테스트 세트로 이미 나뉘어 있음.  

## 3.2 이진 분류기 훈련
문제를 단순화하여 한 가지 숫자만 식별하도록 하는 훈련.  
여기서는 5를 식별하도록 함.  
확률적 경사 하강법, Stochastic Gradient Descent(SGD) 모델을 사용하여 훈련.  
사이킷런의 SGDClassifier 클래스를 사용해 구현할 수 있음  

## 3-3. 성능 측정
### 3-3-1. 교차 검증
Cross-val-score() 함수로 K-폴드 교차 검증을 통해 모델을 평가한다.  
K-폴드 교차 검증: 훈련 세트를 k개로 나누고 평가를 위해 매번 다른 폴드를 떼어 놓고 모델을 K번 훈련함  

#### 정확도(accuracy)의 문제
5는 전체 세트의 10% 정도이므로 무조건 False를 반환해도 90% 가량의 높은 정확도가 나온다. 따라서 정확도는 성능 측정 지표로 선호되지 않는다.

### 3-3-2. 오차 행렬
기본 아이디어: A가 B로 분류된 횟수를 세는 것  
행은 실제 클래스를, 열은 예측한 클래스를 나타냄  

### 3-3-3. 정밀도와 재현율
#### 정밀도
$Precision = \frac{TP}{TP+FP}$  

#### 재현율
$Recall = \frac{TP}{TP+FN}$  

#### $F_{1}$점수
$F_{1}$ 점수는 정밀도와 재현율의 조화 평균이다.  
scikit-learn에서 f1_score() 함수를 호출하여 확인할 수 있다.

### 3.3.4 정밀도 재현율 트레이드오프
정밀도가 높아지면 재현율이 낮아지고 재현율이 높아지면 정밀도가 낮아진다. 따라서 그 중간 어딘가를 선택해야 한다.
SGDClassifier는 결정 임계값을 사용한다. 이 값이 높아지면 정밀도가 높아지고 재현율은 낮아진다.

### 3-3-5 ROC 곡선
수신기 조작 특성 곡선은 위양성에 대한 진양성 비율의 곡선이다.  
이는 민감도에 대한 1-특이도 그래프이기도 하다.  
이 곡선의 곡선 아래의 면적이 넓을수록 좋음  
## 3-4. 다중분류
다중 분류기는 둘 이상의 클래스를 구별할 수 있다.  
OVR, OVA: 각 분류기의 결정 점수중 가장 높은걸 선택하는 전략
OVO: 각 조합마다 분류기를 훈련시키는 것  
서포트 벡터 머신처럼 훈련 세트 크기에 민감한 경우 OVO 선호  

## 3-5. 오차분석
오차 행렬을 이용하면 분류기가 어떤 오류를 범하는지 알 수 있다.  
이를 통해 오차를 분석하여 오차를 줄이기 위해 학습 데이터를 늘리거나 변형되거나 증식할 수 있다.  

## 3-6. 다중 레이블 분류
다중 레이블 분류를 지원하지 않는 모델은 각 특성에 대해 하나의 모델을 학습시켜야 한다. 그리고 이 과정에서 각각의 특성을 사용할 수 있도록 chain 형태로 구현할 수 있다.

## 3-7. 다중 출력 분류
다중 레이블 분류에서 한 레이블이 다중 클래스가 될 수 있도록 한 것.  
값을 2개 이상 가질 수 있다는 의미
